import streamlit as st
from googleapiclient.discovery import build
import re
from googleapiclient.errors import HttpError
import pickle
import os
from datetime import datetime, timedelta
import hmac
import hashlib
import toml

# YouTube Data APIã®APIã‚­ãƒ¼
API_KEY = 'AIzaSyDM2F_A0kreCYAONjzGq4RBvKTvOU3aII4'

# ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆèª­ã¿å–ã‚Š
def get_local_secret(key, default=None):
    try:
        with open('.streamlit/secrets.toml', 'r') as f:
            secrets = toml.load(f)
        return secrets['general'][key]
    except Exception as e:
        return default

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
def get_password():
    try:
        return st.secrets['general']['password']
    except KeyError:
        return get_local_secret('password', 'default_password')

# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
if 'api_requests' not in st.session_state:
    st.session_state.api_requests = 0

# ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
sponsor_patterns = [
    r'(?:æä¾›|ã‚¹ãƒãƒ³ã‚µãƒ¼|å”è³›|PR|åºƒå‘Š|ã‚µãƒãƒ¼ãƒˆ)[:ï¼š]\s*([^ã€\n]+)',
    r'([\w\s]+)ã®æä¾›ã§ãŠé€ã‚Šã—ã¾ã™',
    r'æœ¬å‹•ç”»ã¯([\w\s]+)ã¨ã®ã‚¿ã‚¤ã‚¢ãƒƒãƒ—',
    r'([\w\s]+)æ§˜ã®ã”å”åŠ›ã®ã‚‚ã¨',
    r'sponsored by\s+([\w\s]+)',
    r'æœ¬å‹•ç”»ã¯([\w\s]+)ã®åºƒå‘Šã‚’å«ã¿ã¾ã™',
    r'ç•ªçµ„ã‚¹ãƒãƒ³ã‚µãƒ¼[:ï¼š]?\s*([^\n]+)',
    r'([\w\s]+)æ§˜ã«ã‚ˆã‚‹ç•ªçµ„æä¾›',
    r'æä¾›ï¼š([\w\s]+)',
    r'ã€ç•ªçµ„ã‚¹ãƒãƒ³ã‚µãƒ¼ã€‘\s*([^\n]+)',
]

# é™¤å¤–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
exclude_patterns = [
    r'å‹•ç”»æä¾›',
    r'æ¥½æ›²æä¾›',
    r'éŸ³æ¥½æä¾›',
    r'BGMæä¾›',
]

def extract_sponsors(description):
    sponsors = []
    for pattern in sponsor_patterns:
        matches = re.findall(pattern, description, re.IGNORECASE | re.MULTILINE)
        for match in matches:
            if isinstance(match, tuple):
                sponsors.extend(match)
            else:
                sponsors.append(match)
    
    # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹ã‚¹ãƒãƒ³ã‚µãƒ¼ã‚’é™¤å¤–
    sponsors = [sponsor.strip() for sponsor in sponsors if sponsor.strip() and not any(re.search(ep, sponsor, re.IGNORECASE) for ep in exclude_patterns)]
    return sponsors

def get_video_details(api_key, video_ids):
    youtube = build('youtube', 'v3', developerKey=api_key)
    video_details = []
    
    for i in range(0, len(video_ids), 50):
        chunk = video_ids[i:i+50]
        try:
            details_response = youtube.videos().list(
                id=','.join(chunk),
                part='snippet,statistics,contentDetails'
            ).execute()
            st.session_state.api_requests += 1

            for item in details_response.get('items', []):
                description = item['snippet']['description']
                title = item['snippet']['title']
                sponsors_found = extract_sponsors(description)
                
                if sponsors_found:
                    video_details.append({
                        'title': title,
                        'viewCount': item['statistics'].get('viewCount', 'N/A'),
                        'publishedAt': item['snippet']['publishedAt'],
                        'description': description,
                        'thumbnailUrl': item['snippet']['thumbnails']['high']['url'],
                        'url': f"https://www.youtube.com/watch?v={item['id']}",
                        'sponsors': sponsors_found
                    })
        except HttpError as e:
            st.error(f"å‹•ç”»æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    return video_details

def search_videos_with_paging(api_key, query, max_results_per_page=50, total_results=200):
    cache_file = f"cache_{query.replace(' ', '_')}.pkl"
    if os.path.exists(cache_file) and (datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))).days < 1:
        with open(cache_file, 'rb') as f:
            return pickle.load(f)

    youtube = build('youtube', 'v3', developerKey=api_key)
    video_ids = []
    next_page_token = None

    progress_text = "æ¤œç´¢ä¸­..."
    progress_bar = st.progress(0)

    while len(video_ids) < total_results:
        try:
            search_response = youtube.search().list(
                q=query,
                part='snippet',
                type='video',
                maxResults=max_results_per_page,
                order='relevance',
                pageToken=next_page_token
            ).execute()
            st.session_state.api_requests += 1

            video_ids.extend([item['id']['videoId'] for item in search_response.get('items', [])])
            next_page_token = search_response.get('nextPageToken', None)

            progress = min(len(video_ids) / total_results, 1.0)
            progress_bar.progress(progress, text=progress_text)

            if next_page_token is None:
                break
        except HttpError as e:
            st.error(f"å‹•ç”»ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            break

    progress_bar.empty()
    results = get_video_details(api_key, video_ids[:total_results])
    
    with open(cache_file, 'wb') as f:
        pickle.dump(results, f)
    
    return results

def check_password():
    """Returns `True` if the user had the correct password."""

    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if hmac.compare_digest(st.session_state["password"], get_password()):
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # don't store password
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        # First run, show input for password.
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password", on_change=password_entered, key="password"
        )
        return False
    elif not st.session_state["password_correct"]:
        # Password not correct, show input + error.
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password", on_change=password_entered, key="password"
        )
        st.error("ğŸ˜• ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
        return False
    else:
        # Password correct.
        return True

if check_password():
    # Streamlitã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­å®š
    st.title('YouTube ã‚¹ãƒãƒ³ã‚µãƒ¼å‹•ç”»æ¤œç´¢ã‚¢ãƒ—ãƒª')
    st.write('æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§YouTubeå‹•ç”»ã‚’æ¤œç´¢ã—ã€ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‹•ç”»ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚')

    # æ¤œç´¢ã‚¯ã‚¨ãƒªã®å…¥åŠ›
    query = st.text_input('æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„', 'å°æ¹¾æ—…è¡Œ')

    # æ¤œç´¢ä»¶æ•°ã®è¨­å®š
    total_results = st.slider('æ¤œç´¢ä»¶æ•°', min_value=50, max_value=1000, value=200, step=50)

    # æ¤œç´¢ãƒœã‚¿ãƒ³
    if st.button('æ¤œç´¢'):
        st.write(f'æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰: {query} ã§ã‚¹ãƒãƒ³ã‚µãƒ¼ä»˜ãå‹•ç”»ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™...')
        videos = search_videos_with_paging(API_KEY, query, total_results=total_results)
        
        if videos:
            st.write(f'ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‹•ç”»ãŒ {len(videos)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼')
            for video in videos:
                st.markdown(f"### {video['title']}")
                st.write(f"**è¦–è´å›æ•°**: {video['viewCount']}")
                st.write(f"**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ—¥æ™‚**: {video['publishedAt']}")
                st.image(video['thumbnailUrl'])
                st.write(f"**URL**: [ã“ã¡ã‚‰ã‚’ã‚¯ãƒªãƒƒã‚¯]({video['url']})")
                
                st.write(f"**ã‚¹ãƒãƒ³ã‚µãƒ¼**: {', '.join(video['sponsors'])}")
                
                with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
                    st.write(video['description'])
        else:
            st.write('ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚')

    # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã®è¡¨ç¤º
    st.sidebar.write(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {st.session_state.api_requests} / 10000")

    # å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤º
    st.write("å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: `streamlit run app2.py`")
