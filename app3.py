import streamlit as st
from googleapiclient.discovery import build
import re
from googleapiclient.errors import HttpError
import pickle
import os
from datetime import datetime, timedelta
import hmac
import toml
import glob

# YouTube Data APIã®APIã‚­ãƒ¼
API_KEY = 'AIzaSyDM2F_A0kreCYAONjzGq4RBvKTvOU3aII4'

# YouTubeã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒªã‚¹ãƒˆ
YOUTUBE_CATEGORIES = [
    "ã™ã¹ã¦", "éŸ³æ¥½", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ã‚²ãƒ¼ãƒ ", "ãƒ©ã‚¤ãƒ–", "é‡çƒ", "è¦³å…‰", "æ–™ç†", "è‡ªç„¶", "æœ€è¿‘ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»", "æ–°ã—ã„å‹•ç”»ã®ç™ºè¦‹"
]

# ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆèª­ã¿å–ã‚Š
def get_local_secret(key, default=None):
    try:
        with open('.streamlit/secrets.toml', 'r') as f:
            secrets = toml.load(f)
        return secrets['general'][key]
    except Exception as e:
        return default

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
def get_password():
    try:
        return st.secrets['general']['password']
    except KeyError:
        return get_local_secret('password', 'default_password')

# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
if 'api_requests' not in st.session_state:
    st.session_state.api_requests = 0

# ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
sponsor_patterns = [
    r'(?:æä¾›|ã‚¹ãƒãƒ³ã‚µãƒ¼|å”è³›|PR|åºƒå‘Š|ã‚µãƒãƒ¼ãƒˆ)[:ï¼š]\s*([^ã€\n]+)',
    r'([\w\s]+)ã®æä¾›ã§ãŠé€ã‚Šã—ã¾ã™',
    r'æœ¬å‹•ç”»ã¯([\w\s]+)ã¨ã®ã‚¿ã‚¤ã‚¢ãƒƒãƒ—',
    r'([\w\s]+)æ§˜ã®ã”å”åŠ›ã®ã‚‚ã¨',
    r'sponsored by\s+([\w\s]+)',
    r'æœ¬å‹•ç”»ã¯([\w\s]+)ã®åºƒå‘Šã‚’å«ã¿ã¾ã™',
    r'ç•ªçµ„ã‚¹ãƒãƒ³ã‚µãƒ¼[:ï¼š]?\s*([^\n]+)',
    r'([\w\s]+)æ§˜ã«ã‚ˆã‚‹ç•ªçµ„æä¾›',
    r'æä¾›ï¼š([\w\s]+)',
    r'ã€ç•ªçµ„ã‚¹ãƒãƒ³ã‚µãƒ¼ã€‘\s*([^\n]+)',
]

# é™¤å¤–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆéŸ³æ¥½é–¢é€£ã®æä¾›ã‚’å«ã‚€ï¼‰
exclude_patterns = [
    r'å‹•ç”»æä¾›',
    r'æ¥½æ›²æä¾›',
    r'éŸ³æ¥½æä¾›',
    r'BGMæä¾›',
    r'Production Music by',
    r'epidemicsound\.com',
    r'PIXTA',
    r'ç”˜èŒ¶ã®éŸ³æ¥½å·¥æˆ¿',
    r'musmus\.main\.jp',
    r'NoCopyrightSounds',
    r'Music, Artlist License',
    r'æ ªå¼ä¼šç¤¾ã‚¢ã‚¤ãƒªãƒ³ã‚°',
    r'æ¥½æ›²æä¾›ï¼š.*',  # æ¥½æ›²æä¾›ã§å§‹ã¾ã‚‹å…¨ã¦ã®æ–‡å­—åˆ—ã‚’é™¤å¤–
]

def extract_sponsors(description):
    sponsors = []
    for pattern in sponsor_patterns:
        matches = re.findall(pattern, description, re.IGNORECASE | re.MULTILINE)
        for match in matches:
            if isinstance(match, tuple):
                sponsors.extend(match)
            else:
                sponsors.append(match)
    
    # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹ã‚¹ãƒãƒ³ã‚µãƒ¼ã‚’é™¤å¤–
    sponsors = [sponsor.strip() for sponsor in sponsors if sponsor.strip() and not any(re.search(ep, sponsor, re.IGNORECASE) for ep in exclude_patterns)]
    
    # URLã®ã¿ã®å ´åˆã‚„ã€"Music"ã®ã¿ã®å ´åˆã¯é™¤å¤–
    sponsors = [sponsor for sponsor in sponsors if not sponsor.startswith('http') and not sponsor.startswith('www.') and sponsor.lower() != 'music']
    
    return sponsors

def clear_cache():
    cache_files = glob.glob("cache_*.pkl")
    for file in cache_files:
        os.remove(file)
    st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸã€‚")

def get_video_details(api_key, video_ids):
    youtube = build('youtube', 'v3', developerKey=api_key)
    video_details = []
    
    for i in range(0, len(video_ids), 50):
        chunk = video_ids[i:i+50]
        try:
            details_response = youtube.videos().list(
                id=','.join(chunk),
                part='snippet,statistics,contentDetails'
            ).execute()
            st.session_state.api_requests += 1

            for item in details_response.get('items', []):
                description = item['snippet']['description']
                title = item['snippet']['title']
                sponsors_found = extract_sponsors(description)
                
                video_details.append({
                    'title': title,
                    'viewCount': item['statistics'].get('viewCount', 'N/A'),
                    'publishedAt': item['snippet']['publishedAt'],
                    'description': description,
                    'thumbnailUrl': item['snippet']['thumbnails']['high']['url'],
                    'url': f"https://www.youtube.com/watch?v={item['id']}",
                    'sponsors': sponsors_found
                })
        except HttpError as e:
            st.error(f"å‹•ç”»æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    return video_details

def search_videos_with_paging(api_key, query, max_results_per_page=50, total_results=200, order='relevance', video_category=''):
    cache_file = f"cache_{query.replace(' ', '_')}_{order}_{video_category}.pkl"
    if os.path.exists(cache_file) and (datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))).days < 1:
        with open(cache_file, 'rb') as f:
            return pickle.load(f)

    youtube = build('youtube', 'v3', developerKey=api_key)
    video_ids = []
    next_page_token = None

    progress_text = "æ¤œç´¢ä¸­..."
    progress_bar = st.progress(0)

    while len(video_ids) < total_results:
        try:
            search_params = {
                'q': query,
                'part': 'snippet',
                'type': 'video',
                'maxResults': max_results_per_page,
                'order': order,
                'pageToken': next_page_token
            }
            if video_category:
                search_params['videoCategoryId'] = video_category

            search_response = youtube.search().list(**search_params).execute()
            st.session_state.api_requests += 1

            video_ids.extend([item['id']['videoId'] for item in search_response.get('items', [])])
            next_page_token = search_response.get('nextPageToken', None)

            progress = min(len(video_ids) / total_results, 1.0)
            progress_bar.progress(progress, text=progress_text)

            if next_page_token is None:
                break
        except HttpError as e:
            st.error(f"å‹•ç”»ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            break

    progress_bar.empty()
    results = get_video_details(api_key, video_ids[:total_results])
    
    with open(cache_file, 'wb') as f:
        pickle.dump(results, f)
    
    return results

def get_category_id(youtube, category_name):
    try:
        categories = youtube.videoCategories().list(part='snippet', regionCode='JP').execute()
        for category in categories['items']:
            if category['snippet']['title'].lower() == category_name.lower():
                return category['id']
    except HttpError as e:
        st.error(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼IDã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    return None

def check_password():
    """Returns `True` if the user had the correct password."""

    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if hmac.compare_digest(st.session_state["password"], get_password()):
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # don't store password
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        # First run, show input for password.
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password", on_change=password_entered, key="password"
        )
        return False
    elif not st.session_state["password_correct"]:
        # Password not correct, show input + error.
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password", on_change=password_entered, key="password"
        )
        st.error("ğŸ˜• ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
        return False
    else:
        # Password correct.
        return True

def display_video_info(video, show_sponsors=True):
    st.markdown(f"[{video['title']}]({video['url']})")
    st.write(f"**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ—¥æ™‚**: {video['publishedAt']}")
    if show_sponsors:
        st.write(f"**è¦–è´å›æ•°**: {video['viewCount']}")
        st.image(video['thumbnailUrl'])
        if video['sponsors']:
            st.write(f"**ã‚¹ãƒãƒ³ã‚µãƒ¼**: {', '.join(video['sponsors'])}")
        with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
            st.write(video['description'])

if check_password():
    st.markdown("<h1 style='font-size: 24px;'>YouTube ã‚¹ãƒãƒ³ã‚µãƒ¼å‹•ç”»æ¤œç´¢ã‚¢ãƒ—ãƒª</h1>", unsafe_allow_html=True)
    st.write('YouTubeã®å‹•ç”»ã‚’æ¤œç´¢ã—ã€ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‹•ç”»ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚')

    search_type = st.radio("æ¤œç´¢ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ", ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢", "ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¤œç´¢", "ãƒˆãƒ¬ãƒ³ãƒ‰"])

    if search_type == "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢":
        query = st.text_input('æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„', 'éŸ“å›½')
        category = "ã™ã¹ã¦"
    elif search_type == "ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¤œç´¢":
        category = st.selectbox("ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ", YOUTUBE_CATEGORIES)
        query = category
    else:  # ãƒˆãƒ¬ãƒ³ãƒ‰
        query = ""
        category = "ã™ã¹ã¦"

    total_results = st.slider('æ¤œç´¢ä»¶æ•°', min_value=50, max_value=1000, value=200, step=50)
    order = 'date' if search_type != "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢" else 'relevance'

    # æ¤œç´¢ãƒœã‚¿ãƒ³ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’æ¨ªã«ä¸¦ã¹ã‚‹
    col1, col2 = st.columns(2)
    with col1:
        search_button = st.button('æ¤œç´¢')
    with col2:
        cache_clear_button = st.button('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢')

    if cache_clear_button:
        clear_cache()

    if search_button:
        youtube = build('youtube', 'v3', developerKey=API_KEY)
        category_id = get_category_id(youtube, category) if category != "ã™ã¹ã¦" else ""

        st.write(f'{"ãƒˆãƒ¬ãƒ³ãƒ‰" if search_type == "ãƒˆãƒ¬ãƒ³ãƒ‰" else query} ã§å‹•ç”»ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™...')
        videos = search_videos_with_paging(API_KEY, query, total_results=total_results, order=order, video_category=category_id)
        
        # ä»¥ä¸‹ã€æ—¢å­˜ã®æ¤œç´¢çµæœè¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯
        if videos:
            # æ–°ç€é †ã«ä¸¦ã¹æ›¿ãˆ
            videos = sorted(videos, key=lambda x: x['publishedAt'], reverse=True)
            
            st.write(f'åˆè¨ˆ {len(videos)} ä»¶ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚')
            
            # ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒã‚ã‚‹å‹•ç”»ã¨ãªã„å‹•ç”»ã‚’åˆ†ã‘ã‚‹
            sponsored_videos = [v for v in videos if v['sponsors']]
            non_sponsored_videos = [v for v in videos if not v['sponsors']]
            
            st.write(f'ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‹•ç”»: {len(sponsored_videos)} ä»¶')
            st.write(f'ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãªã„å‹•ç”»: {len(non_sponsored_videos)} ä»¶')
            
            # ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒã‚ã‚‹å‹•ç”»ã‚’è¡¨ç¤º
            if sponsored_videos:
                st.subheader("ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‹•ç”»")
                for video in sponsored_videos:
                    display_video_info(video, show_sponsors=True)
            
            # ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒãªã„å‹•ç”»ã‚’è¡¨ç¤ºï¼ˆç°¡ç•¥åŒ–ã—ãŸæƒ…å ±ï¼‰
            if non_sponsored_videos:
                st.subheader("ã‚¹ãƒãƒ³ã‚µãƒ¼æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãªã„å‹•ç”»")
                for video in non_sponsored_videos:
                    display_video_info(video, show_sponsors=False)
        else:
            st.write('å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚')

    st.sidebar.write(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {st.session_state.api_requests} / 10000")
    st.write("å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: `streamlit run app3.py`")